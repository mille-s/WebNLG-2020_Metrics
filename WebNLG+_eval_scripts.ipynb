{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/WebNLG-2020_Metrics/blob/main/WebNLG%2B_eval_scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NMOtghjMovnO",
        "outputId": "7cfb246a-031d-4f62-d260-fffe3226bb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'GenerationEval'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 85 (delta 37), reused 52 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (85/85), 222.27 KiB | 2.74 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "Cloning into 'bleurt'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 134 (delta 0), reused 17 (delta 0), pack-reused 116 (from 1)\u001b[K\n",
            "Receiving objects: 100% (134/134), 31.28 MiB | 12.72 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "--2024-08-30 18:35:13--  https://storage.googleapis.com/bleurt-oss/bleurt-base-128.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.207, 64.233.170.207, 142.251.175.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405489453 (387M) [application/zip]\n",
            "Saving to: ‘bleurt-base-128.zip’\n",
            "\n",
            "bleurt-base-128.zip 100%[===================>] 386.70M  21.3MB/s    in 19s     \n",
            "\n",
            "2024-08-30 18:35:32 (20.0 MB/s) - ‘bleurt-base-128.zip’ saved [405489453/405489453]\n",
            "\n",
            "Archive:  bleurt-base-128.zip\n",
            "   creating: bleurt-base-128/\n",
            "  inflating: bleurt-base-128/vocab.txt  \n",
            "  inflating: bleurt-base-128/bert_config.json  \n",
            "   creating: bleurt-base-128/variables/\n",
            "  inflating: bleurt-base-128/variables/variables.index  \n",
            "  inflating: bleurt-base-128/variables/variables.data-00000-of-00001  \n",
            "  inflating: bleurt-base-128/bleurt_config.json  \n",
            "  inflating: bleurt-base-128/saved_model.pb  \n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-24.2\n",
            "Processing ./bleurt\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (2.17.0)\n",
            "Requirement already satisfied: tf-slim>=1.1 in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from BLEURT==0.0.2) (0.1.99)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim>=1.1->BLEURT==0.0.2) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->BLEURT==0.0.2) (2024.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->BLEURT==0.0.2) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->BLEURT==0.0.2) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->BLEURT==0.0.2) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow->BLEURT==0.0.2) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow->BLEURT==0.0.2) (0.1.2)\n",
            "Building wheels for collected packages: BLEURT\n",
            "  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BLEURT: filename=BLEURT-0.0.2-py3-none-any.whl size=16456765 sha256=8e08c7ae8f1cbb90d6c8fa42332b66df97d84613088540419ac5fe75deac07f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5bnh80_q/wheels/92/4f/fb/afa555fa27aa9e2c7958df797a62cc4e74f0f459cec9c4fa7c\n",
            "Successfully built BLEURT\n",
            "Installing collected packages: BLEURT\n",
            "Successfully installed BLEURT-0.0.2\n",
            "--2024-08-30 18:35:47--  https://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223646468 (213M) [application/x-gzip]\n",
            "Saving to: ‘meteor-1.5.tar.gz’\n",
            "\n",
            "meteor-1.5.tar.gz    33%[=====>              ]  71.11M   141KB/s    eta 6m 38s "
          ]
        }
      ],
      "source": [
        "#@title 1 - Download resources and clone repos\n",
        "# RUN THIS CELL FIRST; when done, drag the predicted files in the \"hypotheses\" folder\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Download WebNLG+ code\n",
        "! git clone https://github.com/WebNLG/GenerationEval.git\n",
        "\n",
        "# Download BLEURT\n",
        "! git clone https://github.com/google-research/bleurt.git\n",
        "! wget https://storage.googleapis.com/bleurt-oss/bleurt-base-128.zip\n",
        "! unzip bleurt-base-128.zip\n",
        "! rm bleurt-base-128.zip\n",
        "! pip3 install --upgrade pip\n",
        "! pip3 install /content/bleurt/. --user\n",
        "! mv bleurt /content/GenerationEval/metrics\n",
        "! mv bleurt-base-128 /content/GenerationEval/metrics/bleurt\n",
        "\n",
        "# Download METEOR\n",
        "! wget https://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz\n",
        "! tar -xvf meteor-1.5.tar.gz\n",
        "! mv meteor-1.5 /content/GenerationEval/metrics\n",
        "! rm meteor-1.5.tar.gz\n",
        "\n",
        "# Download repos for creating references\n",
        "! git clone https://gitlab.com/webnlg/corpus-reader.git\n",
        "! git clone https://gitlab.com/shimorina/webnlg-dataset.git\n",
        "import os\n",
        "import os.path\n",
        "hypotheses = '/content/hypotheses'\n",
        "if not os.path.exists(hypotheses):\n",
        "  os.makedirs(hypotheses)\n",
        "\n",
        "# Human eval results and more data\n",
        "#! git clone https://github.com/WebNLG/challenge-2020.git\n",
        "\n",
        "# Install Python dependencies\n",
        "! pip3 install nltk==3.5\n",
        "! pip3 install pyter3==0.3\n",
        "! pip3 install razdel==0.5.0\n",
        "# ! pip3 install tabulate==0.8.7\n",
        "! pip3 install tabulate==0.9\n",
        "# ! pip3 install bert-score==0.3.5\n",
        "! pip3 install bert-score==0.3.13\n",
        "! pip install transformers==3.0.1\n",
        "\n",
        "# Download nltk 'punkt'\n",
        "import sys\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ3ZVNMH7b6J"
      },
      "source": [
        "IMPORTANT: Now, for WebNLG+, drag and drop the predicted files in the \"hypotheses\" folder.\n",
        "\n",
        "> Click on the folder icon on the left if you don't see the folders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cFYQwOxGECQt"
      },
      "outputs": [],
      "source": [
        "#@title 2 - Adapt original codes to Colab\n",
        "# RUN THIS CELL SECOND\n",
        "# Adapt evaluation code to Colab; creates an eval_edited.py file which will be run in the final cell\n",
        "# Adapt reference creation code to Colab; creates a benchmark_reader-edited.py and a generate_references-edited.py files which will be run in the next cell\n",
        "\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "def edit_file(code_lines, landmark, fo, new_code):\n",
        "  x = 0\n",
        "  stop = 'no'\n",
        "  for line in code_lines:\n",
        "    if stop == 'no':\n",
        "      if re.search('^from benchmark_reader import Benchmark', line):\n",
        "        fo.write('from benchmark_reader_edited import Benchmark\\n')\n",
        "      elif re.search('^from benchmark_reader import select_files', line):\n",
        "        fo.write('from benchmark_reader_edited import select_files\\n')\n",
        "      # I don't know why it was set like this; by changing it we get all lexicalisations in ru instead of just 3\n",
        "      elif re.search('^            for lex in entry\\.lexs\\[1::2\\]:  # take every second lexicalisation, i\\.e\\. only ru\\n', line):\n",
        "        fo.write('            for lex in entry.lexs:\\n')\n",
        "      # elif re.search(\"^        with open\\(f'reference\", line):\n",
        "      #   fo.write(\"        with open(f'reference{str(j)}', 'w+') as f:\\n\")\n",
        "      elif re.search(landmark, line):\n",
        "        stop = 'yes'\n",
        "        fo.write(new_code)\n",
        "      else:\n",
        "        fo.write(line)\n",
        "\n",
        "# evaluation code\n",
        "path_eval = '/content/GenerationEval/eval.py'\n",
        "eval_code_lines = codecs.open(path_eval, 'r', 'utf-8').readlines()\n",
        "fo = codecs.open('/content/GenerationEval/eval_edited.py', 'w', 'utf-8')\n",
        "\n",
        "for line in eval_code_lines:\n",
        "  # comment sys.argv bc used later in a different way\n",
        "  if re.search('^sys\\.argv = ', line):\n",
        "    fo.write('#sys.argv = sys.argv[:1]\\n')\n",
        "  # adapt paths to Colab repo\n",
        "  elif re.search('^BLEU_PATH = ', line):\n",
        "    fo.write(\"BLEU_PATH = '/content/GenerationEval/metrics/multi-bleu-detok.perl'\\n\")\n",
        "  elif re.search('^METEOR_PATH = ', line):\n",
        "    fo.write(\"METEOR_PATH = '/content/GenerationEval/metrics/meteor-1.5/meteor-1.5.jar'\\n\")\n",
        "  elif re.search('^def bleurt', line):\n",
        "    fo.write('def bleurt(references, hypothesis, num_refs, checkpoint = \"/content/GenerationEval/metrics/bleurt/bleurt-base-128\"):\\n')\n",
        "  # bleurt throws an error if arguments are not flagged (no positional arguments accepted)\n",
        "  elif re.search('^    scores = scorer\\.score\\(refs, cands\\)', line):\n",
        "    fo.write('    scores = scorer.score(references=refs, candidates=cands)\\n')\n",
        "  # argParser needs arguments passed explicitly to run on Colab\n",
        "  elif re.search('^    args = argParser.parse_args\\(\\)', line):\n",
        "    fo.write('    args = argParser.parse_args(sys.argv[1:])\\n')\n",
        "  # add one decimal to the scores to replicate exactly the WebNLG+ results\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['bleu_nltk'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['bleu_nltk'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['meteor'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['meteor'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['chrf\\+\\+'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['chrf++'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['ter'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['ter'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['bert_precision'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['bert_precision'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['bert_recall'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['bert_recall'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['bert_f1'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['bert_f1'], 3))\\n\")\n",
        "  elif re.search(\"^        values.append\\(round\\(result\\['bleurt'\\], 2\\)\\)\", line):\n",
        "    fo.write(\"        values.append(round(result['bleurt'], 3))\\n\")\n",
        "  else:\n",
        "    fo.write(line)\n",
        "\n",
        "fo.close()\n",
        "\n",
        "# reference text creation code\n",
        "path_reader = '/content/corpus-reader/benchmark_reader.py'\n",
        "path_ref_generator = '/content/corpus-reader/generate_references.py'\n",
        "reader_code_lines = codecs.open(path_reader, 'r', 'utf-8').readlines()\n",
        "ref_generator_code_lines = codecs.open(path_ref_generator, 'r', 'utf-8').readlines()\n",
        "fo2 = codecs.open('/content/corpus-reader/benchmark_reader_edited.py', 'w', 'utf-8')\n",
        "fo3 = codecs.open('/content/corpus-reader/generate_references_edited.py', 'w', 'utf-8')\n",
        "\n",
        "# I needed to modify the function that gathers files to process, as I didn't manage to make it work for test data otherwise\n",
        "new_code_reader = \"def select_files(topdir, category='', size=(1, 8)):\\n    finalfiles = []\\n    if topdir.endswith('dev') or topdir.endswith('train'):\\n        finaldirs = [topdir+'/'+str(item)+'triples' for item in range(size[0], size[1])]\\n        for item in finaldirs:\\n            finalfiles += [(item, filename) for filename in sorted(listdir(item)) if category in filename and '.xml' in filename]\\n    else:\\n        finalfiles += [(topdir, filename) for filename in sorted(listdir(topdir)) if 'generation-test-data-with-refs' in filename and '.xml' in filename]\\n    return finalfiles\"\n",
        "# On this file I only changed the paths\n",
        "new_code_ref_generator = \"path = '/content/webnlg-dataset/release_v3.0/en/test'\\nrun_on_corpus_per_lang(path, 'en')\\n# Russian\\npath = '/content/webnlg-dataset/release_v3.0/ru/test'\\nrun_on_corpus_per_lang(path, 'ru')\"\n",
        "\n",
        "edit_file(reader_code_lines, '^def select_files', fo2, new_code_reader)\n",
        "edit_file(ref_generator_code_lines, \"^path = '\\./challenge2020_train_dev_v2\", fo3, new_code_ref_generator)\n",
        "\n",
        "fo2.close()\n",
        "fo3.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iU4X8sPgRexN"
      },
      "outputs": [],
      "source": [
        "#@title 3 - Evaluation function (collect results in log_eval folder after running 4 below)\n",
        "import glob\n",
        "import os\n",
        "\n",
        "shared_task = 'WebNLG+' #@param ['WebNLG+', 'GEM24']\n",
        "lang = \"en\"#@param [\"en\", \"ru\", \"sw\"]\n",
        "#metrics = 'bleu,meteor,ter,chrf++,bert,bleurt'#@param\n",
        "metrics = 'bleu,meteor,chrf++,bert'#@param\n",
        "# small_test = 'yes' if want to test quickly the code with files that have 10 examples.\n",
        "# Expected output (en):\n",
        "#   BLEU    BLEU NLTK    METEOR    chrF++    TER    BERT-SCORE P    BERT-SCORE R    BERT-SCORE F1    BLEURT\n",
        "# ------  -----------  --------  --------  -----  --------------  --------------  ---------------  --------\n",
        "#  73.02        0.726     0.578     0.877  0.194           0.978           0.971            0.974      0.81\n",
        "small_test = 'no'#@param [\"yes\", \"no\"]\n",
        "log_folder = os.path.join('/content', 'log_eval')\n",
        "if not os.path.exists(log_folder):\n",
        "  os.makedirs(log_folder)\n",
        "\n",
        "def run_evaluation(shared_task, lang, metrics, log_folder, small_test):\n",
        "  # metrics = 'bleu,meteor,ter,chrf++,bert,bleurt'\n",
        "  # Approximate times below on English dataset (1779 texts) with no GPU\n",
        "  # Very fast: BLEU, CHRF++ (~15 sec)\n",
        "  # Fast: METEOR (~40 sec)\n",
        "  # Slow: TER (~10 min, can't use GPU)\n",
        "  # Very slow (Need GPU): BertScore, Bleurt (~1h+ or fail without GPU)\n",
        "  num_refs = ''\n",
        "  if shared_task == 'WebNLG+':\n",
        "    if lang == 'en':\n",
        "      num_refs = '4'\n",
        "    elif lang == 'ru':\n",
        "      num_refs = '6'\n",
        "  elif shared_task == 'GEM24':\n",
        "    if lang == 'en':\n",
        "      num_refs = '1'\n",
        "    elif lang == 'sw':\n",
        "      num_refs = '1'\n",
        "\n",
        "  path_code_eval = '/content/GenerationEval/eval_edited.py'\n",
        "  path_hyp_uploaded = '/content/hypotheses/'\n",
        "  if small_test == 'yes':\n",
        "    path_ref_eval = '/content/GenerationEval/data_small/en/references/reference'\n",
        "    path_hyp_eval = '/content/GenerationEval/data_small/en/hypothesis'\n",
        "    log_small = os.path.join(log_folder, 'log_eval_small.txt')\n",
        "    ! python {path_code_eval} -R {path_ref_eval} -H {path_hyp_eval} -m {metrics} | tee {log_small}\n",
        "  else:\n",
        "    path_ref_eval = '/content/GenerationEval/data_to_process/'+lang+'/references/reference'\n",
        "    path_hyp_eval = '/content/GenerationEval/data_to_process/'+lang+'/hypothesis'\n",
        "    for Filepath in glob.glob(os.path.join(path_hyp_uploaded, '*.txt')):\n",
        "      print(f'\\nProcessing {Filepath}...')\n",
        "      log_filename = os.path.join(log_folder, 'log_eval_'+Filepath.rsplit('/',1)[1].split('.')[0]+'.txt')\n",
        "      file_pred_lines = codecs.open(Filepath, 'r', 'utf-8').readlines()\n",
        "      fo = codecs.open(path_hyp_eval, 'w', 'utf-8')\n",
        "      for line in file_pred_lines:\n",
        "        fo.write(line)\n",
        "      fo.close()\n",
        "      ! python {path_code_eval} -R {path_ref_eval} -H {path_hyp_eval} -lng {lang} -nr {num_refs} -m {metrics} | tee {log_filename}\n",
        "\n",
        "  # argParser.add_argument(\"-R\", \"--reference\", help=\"reference translation\", required=True)\n",
        "  # argParser.add_argument(\"-H\", \"--hypothesis\", help=\"hypothesis translation\", required=True)\n",
        "  # argParser.add_argument(\"-lng\", \"--language\", help=\"evaluated language\", default='en')\n",
        "  # argParser.add_argument(\"-nr\", \"--num_refs\", help=\"number of references\", type=int, default=4)\n",
        "  # argParser.add_argument(\"-m\", \"--metrics\", help=\"evaluation metrics to be computed\", default='bleu,meteor,ter,chrf++,bert,bleurt')\n",
        "  # argParser.add_argument(\"-nc\", \"--ncorder\", help=\"chrF metric: character n-gram order (default=6)\", type=int, default=6)\n",
        "  # argParser.add_argument(\"-nw\", \"--nworder\", help=\"chrF metric: word n-gram order (default=2)\", type=int, default=2)\n",
        "  # argParser.add_argument(\"-b\", \"--beta\", help=\"chrF metric: beta parameter (default=2)\", type=float, default=2.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "go_sSKZva8IB"
      },
      "outputs": [],
      "source": [
        "#@title 4 - Prepare files and run evaluation\n",
        "\n",
        "# This cell first creates the reference files (WebNLG+) or copies the reference files and hypotheses (GEM); then the evaluation code is run\n",
        "# RUN THIS CELL THIRD\n",
        "# Create reference files for automatic evaluation\n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "import codecs\n",
        "\n",
        "# Create folders\n",
        "data_to_process_en = '/content/GenerationEval/data_to_process/en/references'\n",
        "data_to_process_ru = '/content/GenerationEval/data_to_process/ru/references'\n",
        "data_to_process_small = '/content/GenerationEval/data_small/en/references'\n",
        "if not os.path.exists(data_to_process_en):\n",
        "  os.makedirs(data_to_process_en)\n",
        "if not os.path.exists(data_to_process_ru):\n",
        "  os.makedirs(data_to_process_ru)\n",
        "if not os.path.exists(data_to_process_small):\n",
        "  os.makedirs(data_to_process_small)\n",
        "\n",
        "def clear_files(folder):\n",
        "  \"Function to clear files from a folder.\"\n",
        "  if os.path.exists(folder) and os.path.isdir(folder):\n",
        "    for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "          os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "          shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "def postproc_and_move(ref_file_path, dest_folder):\n",
        "  short_filename = ref_file_path.split('-')[0]\n",
        "  out_path = os.path.join(dest_folder, short_filename)\n",
        "  fo = codecs.open(out_path, 'w', 'utf-8')\n",
        "  file_lines = codecs.open(ref_file_path, 'r', 'utf-8').readlines()\n",
        "  x = 0\n",
        "  while x < len(file_lines) - 1:\n",
        "    fo.write(file_lines[x])\n",
        "    x = x + 1\n",
        "  # remove last linebreak of the file (creates problems with some metrics)\n",
        "  last_line = file_lines[x].split('\\n')[0]\n",
        "  fo.write(last_line)\n",
        "  fo.close()\n",
        "\n",
        "if small_test == 'yes':\n",
        "  # Create references with 10 sentences to test the metrics quickly\n",
        "  data_ref0 = codecs.open('/content/GenerationEval/data/en/references/reference0', 'r', 'utf-8').readlines()\n",
        "  data_ref1 = codecs.open('/content/GenerationEval/data/en/references/reference1', 'r', 'utf-8').readlines()\n",
        "  data_ref2 = codecs.open('/content/GenerationEval/data/en/references/reference2', 'r', 'utf-8').readlines()\n",
        "  data_ref3 = codecs.open('/content/GenerationEval/data/en/references/reference3', 'r', 'utf-8').readlines()\n",
        "  data_hyp = codecs.open('/content/GenerationEval/data/en/hypothesis', 'r', 'utf-8').readlines()\n",
        "  fo0 = codecs.open('/content/GenerationEval/data_small/en/references/reference0', 'w', 'utf-8')\n",
        "  fo1 = codecs.open('/content/GenerationEval/data_small/en/references/reference1', 'w', 'utf-8')\n",
        "  fo2 = codecs.open('/content/GenerationEval/data_small/en/references/reference2', 'w', 'utf-8')\n",
        "  fo3 = codecs.open('/content/GenerationEval/data_small/en/references/reference3', 'w', 'utf-8')\n",
        "  fo4 = codecs.open('/content/GenerationEval/data_small/en/hypothesis', 'w', 'utf-8')\n",
        "  x = 0\n",
        "  while x < 9:\n",
        "    fo0.write(data_ref0[x])\n",
        "    fo1.write(data_ref1[x])\n",
        "    fo2.write(data_ref2[x])\n",
        "    fo3.write(data_ref3[x])\n",
        "    fo4.write(data_hyp[x])\n",
        "    x = x + 1\n",
        "  fo0.write(data_ref0[x].split('\\n')[0])\n",
        "  fo1.write(data_ref1[x].split('\\n')[0])\n",
        "  fo2.write(data_ref2[x].split('\\n')[0])\n",
        "  fo3.write(data_ref3[x].split('\\n')[0])\n",
        "  fo4.write(data_hyp[x].split('\\n')[0])\n",
        "  fo0.close()\n",
        "  fo1.close()\n",
        "  fo2.close()\n",
        "  fo3.close()\n",
        "  fo4.close()\n",
        "\n",
        "  # Run small eval\n",
        "  run_evaluation(shared_task, lang, metrics, log_folder, small_test)\n",
        "\n",
        "elif shared_task == 'WebNLG+':\n",
        "  # Create references for the test data (en and ru)\n",
        "  path_create_refs = '/content/corpus-reader/generate_references_edited.py'\n",
        "  ! python {path_create_refs}\n",
        "\n",
        "  # Clear EN reference folder\n",
        "  clear_files(data_to_process_en)\n",
        "  # Move EN references to the folder they'll be used from\n",
        "  postproc_and_move('reference0-en.txt', data_to_process_en)\n",
        "  postproc_and_move('reference1-en.txt', data_to_process_en)\n",
        "  postproc_and_move('reference2-en.txt', data_to_process_en)\n",
        "  postproc_and_move('reference3-en.txt', data_to_process_en)\n",
        "  postproc_and_move('reference4-en.txt', data_to_process_en)\n",
        "  # Clean EN files\n",
        "  ! rm 'reference0-en.txt'\n",
        "  ! rm 'reference1-en.txt'\n",
        "  ! rm 'reference2-en.txt'\n",
        "  ! rm 'reference3-en.txt'\n",
        "  ! rm 'reference4-en.txt'\n",
        "\n",
        "  # Clear RU reference folder\n",
        "  clear_files(data_to_process_ru)\n",
        "  # Move RU references to the folder they'll be used from\n",
        "  postproc_and_move('reference0-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference1-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference2-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference3-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference4-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference5-ru.txt', data_to_process_ru)\n",
        "  postproc_and_move('reference6-ru.txt', data_to_process_ru)\n",
        "  # Clean RU files\n",
        "  ! rm 'reference0-ru.txt'\n",
        "  ! rm 'reference1-ru.txt'\n",
        "  ! rm 'reference2-ru.txt'\n",
        "  ! rm 'reference3-ru.txt'\n",
        "  ! rm 'reference4-ru.txt'\n",
        "  ! rm 'reference5-ru.txt'\n",
        "  ! rm 'reference6-ru.txt'\n",
        "\n",
        "  # Run full eval\n",
        "  run_evaluation(shared_task, lang, metrics, log_folder, small_test)\n",
        "\n",
        "elif shared_task == 'GEM24':\n",
        "  # Clear reference folder\n",
        "  clear_files(data_to_process_en)\n",
        "\n",
        "  folder_suffix = '-enAmtRefs' #param['-onlyWebnlgRef', '-enAmtRefs']\n",
        "  # Unzip texts folder\n",
        "  data_folder = '/content/content/d2t_outputs-sampled'+folder_suffix+'_grouped'\n",
        "  zip_name = '/content/d2t_outputs-sampled'+folder_suffix+'_grouped.zip'\n",
        "  if not os.path.exists(data_folder):\n",
        "    ! unzip {zip_name}\n",
        "  # Get list of folders, one folder per dataset\n",
        "  dataset_folders_paths = glob.glob(data_folder+'/d2t_outputs-sampled/*')\n",
        "  for dataset_folder_path in sorted(dataset_folders_paths):\n",
        "    _, tail_dataset = os.path.split(dataset_folder_path)\n",
        "    # Within each dataset folder, get language folders\n",
        "    language_folders_paths = glob.glob(dataset_folder_path+'/*')\n",
        "    for language_folder_path in sorted(language_folders_paths):\n",
        "      language = language_folder_path.split('/')[-1]\n",
        "      print(language_folder_path)\n",
        "      # Within each language folder, get size folders\n",
        "      size_folders_paths = glob.glob(language_folder_path+'/*')\n",
        "      for size_folder_path in sorted(size_folders_paths):\n",
        "        size = size_folder_path.split('/')[-1]\n",
        "        print(f'  {size}')\n",
        "        # Within each size folder, get files (all text files start by a numerical team ID)\n",
        "        reference_files_paths = []\n",
        "        predicted_files_paths = []\n",
        "        text_files_paths = glob.glob(size_folder_path+'/[0-9]*.txt')\n",
        "        for text_file_path in sorted(text_files_paths):\n",
        "          text_filename = text_file_path.split('/')[-1]\n",
        "          # print(f'    {text_filename}')\n",
        "          # In GEM, the reference file has a 0 prefix\n",
        "          if text_filename.startswith('0'):\n",
        "            reference_files_paths.append(text_file_path)\n",
        "          else:\n",
        "            predicted_files_paths.append(text_file_path)\n",
        "\n",
        "        if len(reference_files_paths) > 0:\n",
        "          # Clear hypotheses folder, since we'll copy the GEM files there with this block\n",
        "          clear_files('/content/hypotheses/')\n",
        "          # if there is one reference file, name if \"reference\"\n",
        "          if len(reference_files_paths) == 1:\n",
        "            new_filepath = '/content/GenerationEval/data_to_process/en/references/reference'\n",
        "            shutil.copy(reference_files_paths[0], new_filepath)\n",
        "          # If there are more references, number them\n",
        "          elif len(reference_files_paths) > 1:\n",
        "            for count_ref, reference_files_path in enumerate(sorted(reference_files_paths)):\n",
        "              new_filepath = '/content/GenerationEval/data_to_process/en/references/reference'+count_ref\n",
        "              shutil.copy(reference_files_paths[0], new_filepath)\n",
        "          # Finally, copy the predicted files to the hypotheses folder\n",
        "          for predicted_files_path in sorted(predicted_files_paths):\n",
        "            _, tail_predFilePath = os.path.split(predicted_files_path)\n",
        "            new_filepath = os.path.join('/content/hypotheses/', f'{tail_dataset}_{language}_{tail_predFilePath}.txt')\n",
        "            shutil.copy(predicted_files_path, new_filepath)\n",
        "          # Run full eval for each size\n",
        "          run_evaluation(shared_task, lang, metrics, log_folder, small_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3za-Q6WCTu_B"
      },
      "outputs": [],
      "source": [
        "#@title 5 - Zip and download log files\n",
        "download_log_files = 'yes'#@param['yes', 'no']\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "if download_log_files == 'yes':\n",
        "  from google.colab import files\n",
        "  zip_name_log = '/content/log_eval.zip'\n",
        "  !zip -r {zip_name_log} {log_folder}\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  files.download(zip_name_log)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
